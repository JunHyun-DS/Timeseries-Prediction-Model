{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4a7f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# from sklearnex import patch_sklearn \n",
    "# patch_sklearn()\n",
    "\n",
    "\n",
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Randomforest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# hyper parameter tunning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# LSTM\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.layers import LSTM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c109608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jul 31 16:43:28 2022\n",
    "\n",
    "@author: Junhyun\n",
    "\"\"\"\n",
    "class TimeSeriesRegression():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "    \n",
    "    def TimeSeriesDataTransform(self, data, lag):\n",
    "        \"\"\"\n",
    "        # 참조 코드 : http://103.60.126.183:8150/gidatalab (LSTM)\n",
    "        \n",
    "        데이터를 변환하기 위해서는 Y값이 맨 왼쪽에 위치해있어야함 \n",
    "        \n",
    "        To transoform data to timeseries data, target data(Y) have to be located at leftmost\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : DataFrame\n",
    "            data\n",
    "        lag : int\n",
    "            시계열 예측에서 데이터를 미는 시점 (= Time sequence)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        agg : 시계열 에측이 가능하도록 변환된 데이터\n",
    "\n",
    "        \"\"\"\n",
    "        if isinstance(self.data, np.ndarray):\n",
    "            data = pd.DataFrame(self.data)\n",
    "        elif isinstance(self.data, pd.core.series.Series):\n",
    "            data = pd.DataFrame(self.data)\n",
    "        \n",
    "        n_vars = 1 if type(data) is list else data.shape[1]\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        cols, names = list(), list()\n",
    "\n",
    "        # 입력값의 순서 (t-n, ... t-1)\n",
    "        for i in range(lag, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('%s(t-%d)' % (data.columns[j], i)) for j in range(n_vars)]\n",
    "\n",
    "        # 예측의 순서 (t, t+1, ... t+n)\n",
    "        for i in range(0, 1):\n",
    "            cols.append(df.shift(-i))\n",
    "            if i == 0:\n",
    "                names += [('%s(t)' % (data.columns[j])) for j in range(n_vars)]\n",
    "            else:\n",
    "                names += [('%s(t+%d)' % (data.columns[j], i)) for j in range(n_vars)]\n",
    "\n",
    "        # 합치기\n",
    "        agg = pd.concat(cols, axis=1)\n",
    "        agg.columns = names\n",
    "\n",
    "        # NaN 값의 row를 제거\n",
    "        agg.dropna(inplace=True)\n",
    "        \n",
    "        # 인덱스 초기화\n",
    "        agg = agg.reset_index(drop=True)\n",
    "        \n",
    "        agg = agg.iloc[:,0:(data.shape[1]*lag)+1]\n",
    "\n",
    "        return agg\n",
    "\n",
    "        \n",
    "    # Ridge Regression\n",
    "    def Ridge_regression(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        alphas = np.arange(0.01, 1, 0.03)\n",
    "        ridgecv = RidgeCV(alphas = alphas, cv = 5) \n",
    "        ridgecv.fit(X_train, y_train)\n",
    "        print(\"alpha : %.2f\" % ridgecv.alpha_)\n",
    "\n",
    "        ridge_train_pred = ridgecv.predict(X_train)\n",
    "        ridge_test_pred = ridgecv.predict(X_test)\n",
    "\n",
    "        return({'trainPrediction':ridge_train_pred, 'testPrediction':ridge_test_pred})\n",
    "    \n",
    "    # Random Forest Regression\n",
    "    def Randomforest_regression(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        params = {\n",
    "            'n_estimators' : [100],\n",
    "            'max_depth' : [6,8,10,12],\n",
    "            'min_samples_leaf' : [8,12,8],\n",
    "            'min_samples_split' : [8,16,20]\n",
    "        }\n",
    "\n",
    "        rf = RandomForestRegressor()\n",
    "        grid_cv = GridSearchCV(rf, param_grid=params, cv=5)\n",
    "        grid_cv.fit(X_train, y_train)\n",
    "        print(\"최적 하이퍼 파라미터:\\n\", grid_cv.best_params_)\n",
    "\n",
    "        rf_train_pred = grid_cv.predict(X_train)\n",
    "        rf_test_pred = grid_cv.predict(X_test)\n",
    "\n",
    "        return({'trainPrediction':rf_train_pred, 'testPrediction':rf_test_pred})\n",
    "    \n",
    "    # Support Vector Regression\n",
    "    def Supportvector_regression(self, X_train, X_test, y_train, y_test):\n",
    "\n",
    "        param_grid = [\n",
    "            {'kernel':['linear'], 'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]},\n",
    "            {'kernel':['rbf'], 'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]},\n",
    "            {'gamma':[0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "        ]\n",
    "        svr = SVR()\n",
    "        grid_cv = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "        grid_cv.fit(X_train, y_train)\n",
    "        print(\"최적 하이퍼 파라미터:\\n\", grid_cv.best_params_)\n",
    "\n",
    "        svr_train_pred = grid_cv.predict(X_train)\n",
    "        svr_test_pred = grid_cv.predict(X_test)\n",
    "\n",
    "        return({'trainPrediction':svr_train_pred, 'testPrediction':svr_test_pred})\n",
    "    \n",
    "    # ARIMA\n",
    "    def ARIMA_model(self, y_train, n_periods=5):\n",
    "\n",
    "        auto_arima_model = auto_arima(y_train, \n",
    "                                      start_p=0, max_p=10, \n",
    "                                      start_q=0, max_q=10, \n",
    "                                      seasonal=False,\n",
    "                                      d=1,\n",
    "                                      trace=False,\n",
    "                                      error_action='ignore',  \n",
    "                                      suppress_warnings=True, \n",
    "                                      stepwise=False,\n",
    "                            )\n",
    "        auto_arima_model.fit(y_train)\n",
    "        arima_test_pred = auto_arima_model.predict(n_periods=n_periods)\n",
    "\n",
    "        print(auto_arima_model)\n",
    "\n",
    "        return({'testPrediction':arima_test_pred})\n",
    "\n",
    "    def LSTM_model(self, X_train, X_test, y_train, y_test, epochs=50):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : Array\n",
    "            Train input data, shape=(nrow, lag, ncol)\n",
    "        X_test : Array\n",
    "            Test input data, shape=(nrow, lag, ncol)\n",
    "        y_train : Array\n",
    "            Train input data, shape=(nrow,)\n",
    "        y_test : Array\n",
    "            Train input data, shape=(nrow,)\n",
    "        epochs : int\n",
    "            LSTM 학습횟수\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        trainPrediction : Array\n",
    "            Train Prediction\n",
    "        testPrediction : Array\n",
    "            Test Prediction\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # LSTM의 구조\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(8, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='relu')) # 하나의 층 8개의 노드, return_sequences=True 필수\n",
    "        model.add(LSTM(4, activation='relu', return_sequences=False)) # 하나의층, 4개의 노드, 마지막에는 return_sequences=False\n",
    "        model.add(Dense(1)) # 노드가 하나인 구조를 만들었다 (하나의 예측값으로 표현하기 위해)\n",
    "\n",
    "        # model compile\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "        # fit network\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, verbose=0, shuffle=False) # epochs : 반복횟수\n",
    "\n",
    "        lstm_train_pred = model.predict(X_train)\n",
    "        lstm_test_pred = model.predict(X_test)\n",
    "\n",
    "        return({'trainPrediction':lstm_train_pred, 'testPrediction':lstm_test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf60a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Jul 31 20:18:12 2022\n",
    "\n",
    "@author: Junhyun\n",
    "\"\"\"\n",
    "\n",
    "class Recursive_Bayesian_Ensemble_Model(TimeSeriesRegression):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "    def EnsembleWeight(self, y_test, ensembleModel):\n",
    "        \n",
    "        # test loss of each prediction model\n",
    "        ridge_mse = mean_squared_error(y_test, ensembleModel['ridgeTestPrediction'])\n",
    "        rf_mse = mean_squared_error(y_test, ensembleModel['rfTestPrediction'])\n",
    "        svr_mse = mean_squared_error(y_test, ensembleModel['svrTestPrediction'])\n",
    "        arima_mse = mean_squared_error(y_test, ensembleModel['arimaTestPrediction'])\n",
    "\n",
    "        # Fitness weight of each model\n",
    "        fitnessSum = (1/ridge_mse + 1/rf_mse + 1/svr_mse + 1/arima_mse) # MSE -> fitness Weight\n",
    "        ridge_fitWeight = (1/ridge_mse)  / fitnessSum\n",
    "        rf_fitWeight = (1/rf_mse)  / fitnessSum\n",
    "        svr_fitWeight = (1/svr_mse) / fitnessSum\n",
    "        arima_fitWeight = (1/arima_mse) / fitnessSum\n",
    "        \n",
    "        fitWeight = {'Ridge_FitWeight' : ridge_fitWeight, 'RF_FitWeight':rf_fitWeight, 'SVR_FitWeight' : svr_fitWeight, 'ARIMA_FitWeight' : arima_fitWeight}\n",
    "        \n",
    "        return(fitWeight)\n",
    "    \n",
    "    def EnsemblePrediction(self, X_train, X_test, y_train, y_test, fitWeight):\n",
    "    \n",
    "        ridge = super().Ridge_regression(X_train, X_test, y_train, y_test)\n",
    "        rf = super().Randomforest_regression(X_train, X_test, y_train, y_test)\n",
    "        svr = super().Supportvector_regression(X_train, X_test, y_train, y_test)\n",
    "        arima = super().ARIMA_model(y_train, y_test.shape[0])\n",
    "        \n",
    "        RBEM_train_pred = (ridge['trainPrediction'] * fitWeight['Ridge_FitWeight']) + (rf['trainPrediction'] * fitWeight['RF_FitWeight']) + (svr['trainPrediction'] * fitWeight['SVR_FitWeight'])\n",
    "        RBEM_test_pred = (ridge['testPrediction'] * fitWeight['Ridge_FitWeight']) + (rf['testPrediction'] * fitWeight['RF_FitWeight']) + (svr['testPrediction'] * fitWeight['SVR_FitWeight'])+ arima['testPrediction'] * fitWeight['ARIMA_FitWeight']\n",
    "        \n",
    "        return(\n",
    "            {\n",
    "             'trainPrediction' : RBEM_train_pred, 'testPrediction':RBEM_test_pred, \n",
    "             'ridgeTrainPrediction':ridge['trainPrediction'], 'ridgeTestPrediction':ridge['testPrediction'],\n",
    "             'rfTrainPrediction' : rf['trainPrediction'], 'rfTestPrediction' : rf['testPrediction'],\n",
    "             'svrTrainPrediction' : svr['trainPrediction'], 'svrTestPrediction' : svr['testPrediction'],\n",
    "            'arimaTestPrediction' : arima['testPrediction']\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Recursive Bayesian Update\n",
    "    def BayesianUpdate(self, Prior, Likelihood):\n",
    "        \n",
    "        posterior_Sum = Prior['Ridge_FitWeight']*Likelihood['Ridge_FitWeight'] + Prior['RF_FitWeight']*Likelihood['RF_FitWeight']+Prior['SVR_FitWeight']*Likelihood['SVR_FitWeight'] + Prior['ARIMA_FitWeight']*Likelihood['ARIMA_FitWeight']\n",
    "        Ridge_Updated_Weight = Prior['Ridge_FitWeight']*Likelihood['Ridge_FitWeight'] / posterior_Sum\n",
    "        RF_Updated_Weight = Prior['RF_FitWeight']*Likelihood['RF_FitWeight'] / posterior_Sum\n",
    "        SVR_Updated_Weight = Prior['SVR_FitWeight']*Likelihood['SVR_FitWeight'] / posterior_Sum\n",
    "        ARIMA_Updated_Weight =  Prior['ARIMA_FitWeight']*Likelihood['ARIMA_FitWeight'] / posterior_Sum\n",
    "\n",
    "        updatedFitWeight = {'Ridge_FitWeight' : Ridge_Updated_Weight, 'RF_FitWeight':RF_Updated_Weight, 'SVR_FitWeight' : SVR_Updated_Weight, 'ARIMA_FitWeight':ARIMA_Updated_Weight}\n",
    "        \n",
    "        return(updatedFitWeight)\n",
    "    \n",
    "    # Recursive Bayesian Ensemble Model\n",
    "    def RBEM_model(self, X, y, trainCycle=10, predictionCycle=5, Cycle=5):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Array  \n",
    "            Input data, shape=(nrow, lag, ncol)\n",
    "        y : Array\n",
    "            Output data, shape=(nrow,)\n",
    "        trainCycle : int\n",
    "            며칠 주기로 학습할 것인지 \n",
    "        predictionCycle : int\n",
    "            며칠 주기로 예측할 것인지\n",
    "        Cycle : int\n",
    "            위 과정을 몇번 반복할 것인지\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        recursive_test_pred : Array\n",
    "            test 데이터를 recursive하게 예측한 결과\n",
    "\n",
    "\n",
    "        예시)\n",
    "        1row = 1일일때, \n",
    "        trainCycle = 5 -> 5일 주기로 학습\n",
    "        predictionCycle = 2 -> 2일 주기로 예측\n",
    "\n",
    "        1월 1일 데이터가 있다고 가정\n",
    "\n",
    "        - 1월 1일 ~ 1월 5일 (5일) 학습 후, 1월 6일~1월 7일 (2일) 예측 (1cycle)\n",
    "        - 1월 3일 ~ 1월 7일 (5일) 학습 후, 1월 8일~1월 9일 (2일) 예측 (2cycle) (1월 6일은 실제 데이터임 (예측한 데이터 X)) (현재시점까지 왔다고 가정)\n",
    "        - 1월 5일 ~ 1월 9일 (5일) 학습 후, 1월 10일~1월 11일 (2일) (1일) 예측 (3cycle) (1월 7일은 실제 데이터임 (예측한 데이터 X)) (현재시점까지 왔다고 가정)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Recursive Prediction\n",
    "        RBEM_test_pred = np.array([])\n",
    "        Ridge_test_pred = np.array([])\n",
    "        RF_test_pred = np.array([])\n",
    "        SVR_test_pred = np.array([])\n",
    "        ARIMA_test_pred = np.array([])\n",
    "        y_test = np.array([])\n",
    "        \n",
    "        # Prior of Ensemble Weight\n",
    "        prior_fitWeight = {'Ridge_FitWeight' : 1/3, 'RF_FitWeight':1/3, 'SVR_FitWeight' : 1/3, 'ARIMA_FitWeight':1/3}\n",
    "        \n",
    "        for i in range(Cycle):\n",
    "\n",
    "            # Recursive prediction\n",
    "            recursive_X_train = X[(predictionCycle*i):(trainCycle+predictionCycle*i)]\n",
    "            recursive_X_test = X[(trainCycle+predictionCycle*i):(trainCycle+predictionCycle*(i+1))]\n",
    "            \n",
    "            recursive_y_train = y[(predictionCycle*i):(trainCycle+predictionCycle*i),]\n",
    "            recursive_y_test = y[(trainCycle+predictionCycle*i):(trainCycle+predictionCycle*(i+1)),]\n",
    "            \n",
    "            y_test = np.append(y_test, recursive_y_test.values)\n",
    "            \n",
    "            ensemble_pred = self.EnsemblePrediction(recursive_X_train, recursive_X_test, recursive_y_train, recursive_y_test, prior_fitWeight)\n",
    "                            \n",
    "            # Bayesian Ensemble Prediction\n",
    "            RBEM_test_pred = np.append(RBEM_test_pred, ensemble_pred['testPrediction'])\n",
    "            \n",
    "            # Comprised Model of Ensemble Model\n",
    "            Ridge_test_pred = np.append(Ridge_test_pred, ensemble_pred['ridgeTestPrediction'])                    \n",
    "            RF_test_pred = np.append(RF_test_pred, ensemble_pred['rfTestPrediction'])                  \n",
    "            SVR_test_pred = np.append(SVR_test_pred, ensemble_pred['svrTestPrediction'])\n",
    "            ARIMA_test_pred = np.append(ARIMA_test_pred, ensemble_pred['arimaTestPrediction'])\n",
    "            \n",
    "            # likelihood of Ensemble Weight\n",
    "            likelihood_fitWeight = self.EnsembleWeight(recursive_y_test.values, ensemble_pred)\n",
    "            \n",
    "            # Bayesian Update Ensemble Weights\n",
    "            prior_fitWeight = self.BayesianUpdate(prior_fitWeight, likelihood_fitWeight)\n",
    "            \n",
    "        return(\n",
    "            { \n",
    "                'RBEM_test_pred' : RBEM_test_pred,\n",
    "                'Ridge_test_pred': Ridge_test_pred,\n",
    "                'RF_test_pred' : RF_test_pred,\n",
    "                'SVR_test_pred' : SVR_test_pred,\n",
    "                'ARIMA_test_pred' : ARIMA_test_pred,\n",
    "                'y_test' : y_test\n",
    "            }\n",
    "        \n",
    "        )\n",
    "        \n",
    "    def maxCycleNum(self, data, trainCycle=10, predictionCycle=5):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : DataFrame\n",
    "            data\n",
    "        trainCycle : int\n",
    "            며칠 주기로 학습할 것인지 \n",
    "        predictionCycle : int\n",
    "            며칠 주기로 예측할 것인지\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        maxCycle : int\n",
    "            Recursive 하게 예측할 수 있는 최대 cycle 수\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        maxCycle = int((data.shape[0] - trainCycle) / predictionCycle) - 1\n",
    "\n",
    "        print('Max Cycle Number : %d' % maxCycle)\n",
    "\n",
    "        return(maxCycle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b36ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "data = iris['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5061cc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "640af5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 선언\n",
    "RBEM = Recursive_Bayesian_Ensemble_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "071e6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed = RBEM.TimeSeriesDataTransform(data, lag=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e463af89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)(t-3)</th>\n",
       "      <th>sepal width (cm)(t-3)</th>\n",
       "      <th>petal length (cm)(t-3)</th>\n",
       "      <th>petal width (cm)(t-3)</th>\n",
       "      <th>sepal length (cm)(t-2)</th>\n",
       "      <th>sepal width (cm)(t-2)</th>\n",
       "      <th>petal length (cm)(t-2)</th>\n",
       "      <th>petal width (cm)(t-2)</th>\n",
       "      <th>sepal length (cm)(t-1)</th>\n",
       "      <th>sepal width (cm)(t-1)</th>\n",
       "      <th>petal length (cm)(t-1)</th>\n",
       "      <th>petal width (cm)(t-1)</th>\n",
       "      <th>sepal length (cm)(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)(t-3)  sepal width (cm)(t-3)  petal length (cm)(t-3)  \\\n",
       "0                     5.1                    3.5                     1.4   \n",
       "1                     4.9                    3.0                     1.4   \n",
       "2                     4.7                    3.2                     1.3   \n",
       "3                     4.6                    3.1                     1.5   \n",
       "4                     5.0                    3.6                     1.4   \n",
       "\n",
       "   petal width (cm)(t-3)  sepal length (cm)(t-2)  sepal width (cm)(t-2)  \\\n",
       "0                    0.2                     4.9                    3.0   \n",
       "1                    0.2                     4.7                    3.2   \n",
       "2                    0.2                     4.6                    3.1   \n",
       "3                    0.2                     5.0                    3.6   \n",
       "4                    0.2                     5.4                    3.9   \n",
       "\n",
       "   petal length (cm)(t-2)  petal width (cm)(t-2)  sepal length (cm)(t-1)  \\\n",
       "0                     1.4                    0.2                     4.7   \n",
       "1                     1.3                    0.2                     4.6   \n",
       "2                     1.5                    0.2                     5.0   \n",
       "3                     1.4                    0.2                     5.4   \n",
       "4                     1.7                    0.4                     4.6   \n",
       "\n",
       "   sepal width (cm)(t-1)  petal length (cm)(t-1)  petal width (cm)(t-1)  \\\n",
       "0                    3.2                     1.3                    0.2   \n",
       "1                    3.1                     1.5                    0.2   \n",
       "2                    3.6                     1.4                    0.2   \n",
       "3                    3.9                     1.7                    0.4   \n",
       "4                    3.4                     1.4                    0.3   \n",
       "\n",
       "   sepal length (cm)(t)  \n",
       "0                   4.6  \n",
       "1                   5.0  \n",
       "2                   5.4  \n",
       "3                   4.6  \n",
       "4                   5.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2847bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reframed.iloc[:,0:-1]\n",
    "y = reframed.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68f95e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_Train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e72545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Cycle Number : 18\n"
     ]
    }
   ],
   "source": [
    "maxCycle = RBEM.maxCycleNum(X, trainCycle=50, predictionCycle=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fbb05d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 12, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'gamma': 0.1}\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 12, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 10.0, 'kernel': 'rbf'}\n",
      " ARIMA(3,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 12, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'gamma': 0.01}\n",
      " ARIMA(3,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 1.0, 'kernel': 'rbf'}\n",
      " ARIMA(3,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'gamma': 0.01}\n",
      " ARIMA(3,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.01\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.01, 'kernel': 'linear'}\n",
      " ARIMA(3,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'gamma': 0.01}\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.01\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'gamma': 0.1}\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 10, 'min_samples_leaf': 12, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.01, 'kernel': 'linear'}\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 12, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.0001, 'kernel': 'rbf'}\n",
      " ARIMA(3,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 12, 'min_samples_leaf': 12, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.01, 'kernel': 'linear'}\n",
      " ARIMA(2,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 6, 'min_samples_leaf': 12, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.1, 'kernel': 'linear'}\n",
      " ARIMA(2,1,1)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 12, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.1, 'kernel': 'linear'}\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'gamma': 0.01}\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.1, 'kernel': 'linear'}\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'gamma': 0.1}\n",
      " ARIMA(4,1,0)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 16, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'C': 0.1, 'kernel': 'linear'}\n",
      " ARIMA(4,1,1)(0,0,0)[0] intercept\n",
      "alpha : 0.97\n",
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "최적 하이퍼 파라미터:\n",
      " {'gamma': 0.1}\n",
      " ARIMA(0,1,4)(0,0,0)[0] intercept\n"
     ]
    }
   ],
   "source": [
    "RBEM_pred = RBEM.RBEM_model(X, y, trainCycle=50, predictionCycle=5, Cycle=maxCycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "460bf35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RBEM_test_pred': array([8.14440028, 8.07200555, 8.06005006, 8.16664751, 8.12145846,\n",
       "        5.78477576, 5.4676118 , 6.03983109, 5.51389034, 5.65895807,\n",
       "        5.92545183, 5.7845455 , 5.82522468, 5.79333483, 5.8713135 ,\n",
       "        5.8426707 , 5.88372637, 5.95190689, 5.72479797, 6.01625124,\n",
       "        5.8213482 , 6.09100351, 5.91924959, 5.90775163, 6.03947481,\n",
       "        6.28677338, 6.29351527, 6.13113079, 5.97481461, 6.099846  ,\n",
       "        5.86093516, 6.04155825, 6.08027941, 5.83151769, 6.05142072,\n",
       "        6.17874643, 5.8002168 , 6.03186279, 5.83599884, 6.07943075,\n",
       "        6.12643477, 5.67784106, 5.65314645, 5.88626228, 5.86011209,\n",
       "        5.9340947 , 5.89740655, 5.75829573, 5.94726315, 6.10414396,\n",
       "        6.15660475, 6.29108224, 6.19404258, 6.32552943, 6.28898302,\n",
       "        6.3076516 , 6.2434519 , 6.57000063, 6.72768069, 6.38738063,\n",
       "        6.40192932, 6.48931025, 6.42362479, 6.4485017 , 6.51924287,\n",
       "        6.65226864, 6.57588866, 6.50805578, 6.47219734, 6.36434736,\n",
       "        6.50299982, 6.68272532, 6.47374155, 6.63942004, 6.6261245 ,\n",
       "        6.34486707, 6.33641199, 6.32001915, 6.21742508, 6.27556562,\n",
       "        6.66384917, 6.54745689, 6.52412814, 5.97503685, 6.65769661,\n",
       "        6.8185394 , 6.73242271, 6.19101582, 6.41090069, 6.27060787]),\n",
       " 'Ridge_test_pred': array([6.25038198, 5.98868444, 5.97472941, 6.10506028, 6.03495479,\n",
       "        5.57616326, 5.38240919, 6.11090516, 5.21633733, 5.56532157,\n",
       "        6.23320312, 5.75847971, 5.81925708, 5.77001817, 5.9349039 ,\n",
       "        5.85763829, 5.90512491, 6.02337013, 5.51128792, 6.20505578,\n",
       "        5.69001773, 6.15605891, 5.92936335, 5.94574894, 6.08248125,\n",
       "        6.24206683, 6.16836328, 5.66472965, 5.58079503, 6.02043808,\n",
       "        5.85514648, 6.13762144, 6.06993732, 5.74054244, 6.1378785 ,\n",
       "        6.13933643, 5.52688088, 5.91855408, 5.84212424, 6.22239033,\n",
       "        6.2085676 , 5.65002761, 5.57318038, 6.01366739, 5.94533482,\n",
       "        5.98646915, 5.86328462, 5.59759138, 6.0373064 , 6.31435289,\n",
       "        6.48090231, 6.67920415, 6.48968836, 6.78311084, 6.69415108,\n",
       "        6.3441715 , 6.11513088, 6.73454464, 6.97903322, 6.50592179,\n",
       "        6.40356691, 6.57403978, 6.55216507, 6.50809811, 6.55773693,\n",
       "        6.86397243, 6.63132142, 6.6046322 , 6.50668145, 6.45166072,\n",
       "        6.37648501, 6.72469611, 6.43324568, 6.68667348, 6.61524932,\n",
       "        6.3192721 , 6.34633993, 6.28305976, 6.21686217, 6.18220524,\n",
       "        6.72837486, 6.46296954, 6.97637391, 5.80681539, 6.65238304,\n",
       "        6.93585883, 6.8247385 , 6.05201976, 6.33075593, 6.13951181]),\n",
       " 'RF_test_pred': array([5.36105536, 5.36253613, 5.35823851, 5.35823851, 5.35823851,\n",
       "        5.43360607, 5.56784943, 5.51099003, 5.40427284, 5.57873871,\n",
       "        5.83096202, 5.83575323, 5.81204526, 5.82620836, 5.8185068 ,\n",
       "        5.95121808, 5.89261893, 5.93868159, 5.87207126, 5.96594757,\n",
       "        5.8130873 , 6.08006098, 5.83838596, 5.81867063, 6.05101188,\n",
       "        6.11714301, 6.16019905, 6.11512249, 5.84398982, 5.92621562,\n",
       "        5.89964001, 5.96344163, 6.09100671, 5.8533457 , 5.96976389,\n",
       "        6.20616183, 5.93277503, 6.0340756 , 5.85333747, 5.93170967,\n",
       "        6.12791427, 5.61712532, 5.66222777, 5.71696112, 5.71749195,\n",
       "        5.90862118, 5.93278907, 5.80304439, 5.89065422, 6.06414546,\n",
       "        5.99218715, 6.08730286, 6.07615592, 6.08169758, 6.06957414,\n",
       "        6.17321031, 6.19859556, 6.23997247, 6.25839543, 6.22613534,\n",
       "        6.40081683, 6.38178736, 6.34461632, 6.34649027, 6.3868373 ,\n",
       "        6.55062805, 6.43602468, 6.36815323, 6.40924861, 6.35666942,\n",
       "        6.56895793, 6.68925224, 6.5805944 , 6.64138509, 6.75167569,\n",
       "        6.45590114, 6.51123856, 6.47369662, 6.27193329, 6.48740441,\n",
       "        6.64666902, 6.64457856, 6.01703108, 5.88103717, 6.6839137 ,\n",
       "        6.77771191, 6.80053682, 6.48564162, 6.67062164, 6.63370405]),\n",
       " 'SVR_test_pred': array([6.22529008, 6.23206317, 6.17818988, 6.33139185, 6.2296707 ,\n",
       "        6.32498273, 5.47251023, 6.44773735, 5.99596042, 5.72209009,\n",
       "        5.85538631, 5.8384279 , 5.86688933, 5.76217678, 5.90669015,\n",
       "        5.79368232, 5.79274144, 5.97150605, 5.69440633, 5.98087919,\n",
       "        5.86367208, 6.0373026 , 5.96181259, 5.91587371, 5.94219278,\n",
       "        6.23269979, 6.23859979, 6.03139979, 5.85469979, 5.84139979,\n",
       "        5.83594155, 6.01051747, 6.11359972, 5.96119489, 6.04345658,\n",
       "        6.16924029, 5.91522187, 6.12758294, 5.76972324, 6.064994  ,\n",
       "        5.98694623, 5.80625216, 5.7715136 , 5.90468319, 5.91205457,\n",
       "        5.89999103, 5.89997388, 5.89992752, 5.90004395, 5.90005458,\n",
       "        5.90614089, 5.99939958, 5.92454841, 5.98687328, 5.99181259,\n",
       "        6.41749263, 6.5207744 , 6.72118427, 6.96125554, 6.40427435,\n",
       "        6.40020586, 6.496393  , 6.36495593, 6.4747819 , 6.59103087,\n",
       "        6.53959581, 6.62605458, 6.52217125, 6.48585023, 6.29256073,\n",
       "        6.59463684, 6.62962702, 6.43595284, 6.58358779, 6.54075069,\n",
       "        6.29067753, 6.19806169, 6.24557984, 6.17759816, 6.2187114 ,\n",
       "        6.60518925, 6.54959053, 6.49431736, 6.25474739, 6.63596339,\n",
       "        6.62518288, 6.52903391, 6.29344345, 6.42462245, 6.32473854]),\n",
       " 'ARIMA_test_pred': array([6.59647342, 6.63273291, 6.6689924 , 6.70525188, 6.74151137,\n",
       "        5.92509759, 5.44885474, 6.15528539, 5.46425573, 5.94173279,\n",
       "        5.71753342, 5.61791456, 5.78328546, 5.82493775, 5.80270948,\n",
       "        5.67977792, 6.03302092, 5.78439283, 5.91369917, 5.81440099,\n",
       "        6.06447961, 6.17281612, 6.17108566, 6.25595049, 6.22071357,\n",
       "        6.74148904, 6.77260796, 6.8436476 , 6.85334309, 6.89771933,\n",
       "        5.63837014, 5.746174  , 5.69672085, 5.73905193, 5.72781246,\n",
       "        6.59247515, 6.48030301, 6.60458618, 6.59069689, 6.65754856,\n",
       "        5.99837855, 5.91422821, 5.99024241, 5.97545995, 6.01214977,\n",
       "        5.8594067 , 5.92710353, 5.847825  , 6.00124694, 5.92070623,\n",
       "        6.3632935 , 6.56006514, 6.64187304, 6.56157531, 6.62225183,\n",
       "        6.83634406, 5.53605507, 7.77731601, 5.79102452, 6.73894585,\n",
       "        6.6798535 , 6.6942852 , 6.7087169 , 6.7231486 , 6.7375803 ,\n",
       "        6.69807994, 6.71163741, 6.72519488, 6.73875236, 6.75230983,\n",
       "        6.78061415, 6.79352582, 6.8064375 , 6.81934917, 6.83226085,\n",
       "        6.37006182, 6.4308892 , 6.71690265, 6.43320845, 6.43920413,\n",
       "        6.82207472, 6.69577726, 6.94814789, 7.3986241 , 7.12331129,\n",
       "        6.75486608, 6.92804456, 7.12829546, 6.97535741, 7.00084527]),\n",
       " 'y_test': array([5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6, 6.7,\n",
       "        5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7, 6. ,\n",
       "        5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5, 6.1,\n",
       "        5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3, 6.5,\n",
       "        7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5, 7.7,\n",
       "        7.7, 6. , 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2, 7.4,\n",
       "        7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6. , 6.9, 6.7, 6.9, 5.8])}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBEM_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe142a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(RBEM_pred['RBEM_test_pred'], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273e225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
